# SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

services:
  api:
    build:
      context: ..
      dockerfile: infra/docker/api.Dockerfile
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - ../apps/api/.env
    environment:
      - DEBUG=false
      - STORAGE_BACKEND=${STORAGE_BACKEND:-local}
      - UPLOAD_DIR=/app/uploads
      - TEMPLATES_DIR=/app/templates
      - MAX_CONCURRENT_TRANSCRIPTIONS=${MAX_CONCURRENT_TRANSCRIPTIONS:-3}
      - NUMBA_CACHE_DIR=/tmp/numba_cache
      - NUMBA_DISABLE_CACHING=1
    volumes:
      - api_uploads:/app/uploads
      - api_logs:/app/logs
      - ../apps/api/.env:/app/.env:ro
    networks:
      - ambient-network
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import requests; requests.get('http://localhost:8000/api/health/', timeout=5)",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ui:
  #   build:
  #     context: ..
  #     dockerfile: infra/docker/ui.dev.Dockerfile
  #   restart: unless-stopped
  #   # No external ports - accessed through reverse proxy only
  #   env_file:
  #     - ../apps/ui/.env
  #   environment:
  #     - VITE_API_BASE=/api
  #   depends_on:
  #     - api
  #   networks:
  #     - ambient-network
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 512M
  #       reservations:
  #         memory: 256M
  #   healthcheck:
  #     test:
  #       [
  #         "CMD",
  #         "wget",
  #         "--no-verbose",
  #         "--tries=1",
  #         "--spider",
  #         "http://localhost:80/",
  #       ]
  #     interval: 30s
  #     timeout: 5s
  #     retries: 3
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "5m"
  #       max-file: "3"

  # Nginx reverse proxy for production using approved Ubuntu 24.04 base
  # nginx:
  #   build:
  #     context: .
  #     dockerfile: docker/nginx.ubuntu.Dockerfile
  #   restart: unless-stopped
  #   ports:
  #     - "80:80" # HTTP traffic
  #     - "443:443" # HTTPS traffic
  #   volumes:
  #     - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
  #     - ./docker/default.conf:/etc/nginx/conf.d/default.conf:ro
  #     - ./nginx/ssl:/etc/nginx/ssl:ro
  #     - nginx_logs:/var/log/nginx
  #   depends_on:
  #     - ui
  #     - api
  #   networks:
  #     - ambient-network
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 256M
  #       reservations:
  #         memory: 128M
  #   healthcheck:
  #     test:
  #       [
  #         "CMD",
  #         "wget",
  #         "--no-verbose",
  #         "--tries=1",
  #         "--spider",
  #         "http://localhost:80/",
  #       ]
  #     interval: 30s
  #     timeout: 5s
  #     retries: 3

  # NVIDIA Parakeet NIM for local Riva ASR
  # Use profile 'riva-nim' to deploy: docker-compose --profile riva-nim up
  parakeet-nim:
    image: nvcr.io/nim/nvidia/parakeet-1-1b-ctc-en-us:latest
    container_name: parakeet-1-1b-ctc-en-us
    restart: unless-stopped
    # profiles:
    #   - riva-nim
    runtime: nvidia
    environment:
      - NGC_API_KEY=${NGC_API_KEY}
      - NIM_HTTP_API_PORT=9000
      - NIM_GRPC_API_PORT=50051
      - NIM_TAGS_SELECTOR=name=parakeet-1-1b-ctc-en-us,mode=all,vad=silero,diarizer=sortformer
    ports:
      - "9000:9000"
      - "50051:50051"
    shm_size: 8gb
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
    networks:
      - ambient-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # NVIDIA LLM NIM for self-hosted Llama-3.3-Nemotron-Super-49B
  # Use profile 'riva-nim' to deploy: docker-compose --profile riva-nim up
  llama-nim:
    image: nvcr.io/nim/nvidia/llama-3.3-nemotron-super-49b-v1:latest
    container_name: llama-3.3-nemotron-super-49b-v1
    restart: unless-stopped
    # profiles:
    #   - riva-nim
    runtime: nvidia
    ports:
      - "8001:8000"
    shm_size: 16gb
    volumes:
      - nim-llm-cache:/opt/nim/.cache
    environment:
      - NIM_CACHE_PATH=/opt/nim/.cache
      - NGC_API_KEY=${NGC_API_KEY}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["all"]
              capabilities: [gpu]
    networks:
      - ambient-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health"]
      interval: 60s
      timeout: 30s
      retries: 10
      start_period: 1800s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  ambient-network:
    driver: bridge

volumes:
  api_uploads:
    driver: local
  api_logs:
    driver: local
  # nginx_logs:
  #   driver: local
  nim-llm-cache:
    driver: local
