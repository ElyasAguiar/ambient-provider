services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - "8000:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    env_file:
      - .env
    environment:
      - DEBUG=false
      - NVIDIA_API_KEY=${NVIDIA_API_KEY}
      - STORAGE_BACKEND=${STORAGE_BACKEND:-local}
      - UPLOAD_DIR=/app/uploads
      - TEMPLATES_DIR=/app/templates
      - NUMBA_CACHE_DIR=/tmp/numba_cache
      - NUMBA_DISABLE_CACHING=1
      - DATABASE_URL=${DATABASE_URL:-postgresql+asyncpg://scribehub:scribehub@postgres:5432/scribehub}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio.ambient-provider.orb.local}
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin}
      - MINIO_BUCKET_NAME=${MINIO_BUCKET_NAME:-transcriptions}
      - MINIO_USE_SSL=${MINIO_USE_SSL:-false}
      - TRANSCRIPTION_JOBS_STREAM=${TRANSCRIPTION_JOBS_STREAM:-transcription-jobs}
      - TRANSCRIPTION_RESULTS_STREAM=${TRANSCRIPTION_RESULTS_STREAM:-transcription-results}
      - TRANSCRIPTION_DLQ_STREAM=${TRANSCRIPTION_DLQ_STREAM:-transcription-jobs-dlq}
    command:
      [
        "uvicorn",
        "ambient_scribe.main:app",
        "--host",
        "0.0.0.0",
        "--port",
        "8000",
        "--workers",
        "4",
        "--reload-dir",
        "/app",
      ]
    networks:
      - ambient-network
    depends_on:
      - postgres
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    extra_hosts:
      - "host.docker.internal:host-gateway"
    env_file:
      - .env
    environment:
      - DEBUG=true
      - NVIDIA_API_KEY=${NVIDIA_API_KEY}
      - DATABASE_URL=postgresql+asyncpg://scribehub:scribehub@postgres:5432/scribehub
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio.ambient-provider.orb.local}
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin}
      - MINIO_BUCKET_NAME=${MINIO_BUCKET_NAME:-transcriptions}
      - MINIO_USE_SSL=${MINIO_USE_SSL:-false}
      - TEMPLATES_DIR=/app/templates
      - NUMBA_CACHE_DIR=/tmp/numba_cache
      - NUMBA_DISABLE_CACHING=1
    command: ["arq", "ambient_scribe.workers.transcription.WorkerSettings"]
    networks:
      - ambient-network
    depends_on:
      - postgres
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  stream-consumer:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"
    env_file:
      - .env
    environment:
      - DEBUG=false
      - DATABASE_URL=postgresql+asyncpg://scribehub:scribehub@postgres:5432/scribehub
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio.ambient-provider.orb.local}
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin}
      - MINIO_BUCKET_NAME=${MINIO_BUCKET_NAME:-transcriptions}
      - MINIO_USE_SSL=${MINIO_USE_SSL:-false}
      - TRANSCRIPTION_JOBS_STREAM=${TRANSCRIPTION_JOBS_STREAM:-transcription-jobs}
      - TRANSCRIPTION_RESULTS_STREAM=${TRANSCRIPTION_RESULTS_STREAM:-transcription-results}
      - TRANSCRIPTION_DLQ_STREAM=${TRANSCRIPTION_DLQ_STREAM:-transcription-jobs-dlq}
    command:
      [
        "faststream",
        "run",
        "ambient_scribe.stream_broker:app",
        "--workers",
        "2",
      ]
    networks:
      - ambient-network
    depends_on:
      - postgres
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  postgres:
    image: postgres:16-alpine
    container_name: ambient-scribe-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: scribehub
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-scribehub}
      POSTGRES_DB: scribehub
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ambient-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # # NVIDIA Parakeet NIM for local ASR (modelo de transcrição)
  # parakeet-nim:
  #   image: nvcr.io/nim/nvidia/parakeet-1-1b-ctc-en-us:latest
  #   container_name: parakeet-nim
  #   restart: unless-stopped
  #   runtime: nvidia
  #   environment:
  #     - NGC_API_KEY=${NGC_API_KEY}
  #     - NIM_HTTP_API_PORT=9000
  #     - NIM_GRPC_API_PORT=50051
  #     - NIM_TAGS_SELECTOR=name=parakeet-1-1b-ctc-en-us,mode=streaming,vad=silero,diarizer=sortformer
  #   ports:
  #     - "9000:9000"
  #     - "50051:50051"
  #   shm_size: 6gb
  #   volumes:
  #     - parakeet_cache:/opt/nim/.cache
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 22G
  #       reservations:
  #         memory: 12G
  #         devices:
  #           - driver: nvidia
  #             device_ids: ["0"]
  #             capabilities: [gpu]
  #   networks:
  #     - ambient-network
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:9000/v1/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 300s
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

  # # NVIDIA LLM NIM for Llama-3.3-Nemotron-Super-49B
  # llama-nim:
  #   image: nvcr.io/nim/nvidia/llama-3.3-nemotron-super-49b-v1:latest
  #   container_name: llama-nim
  #   restart: unless-stopped
  #   runtime: nvidia
  #   ports:
  #     - "8001:8000"
  #   shm_size: 16gb
  #   volumes:
  #     - llama_cache:/opt/nim/.cache
  #   environment:
  #     - NIM_CACHE_PATH=/opt/nim/.cache
  #     - NGC_API_KEY=${NGC_API_KEY}
  #     - NVIDIA_VISIBLE_DEVICES=all
  #     - NVIDIA_DRIVER_CAPABILITIES=compute,utility
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 48G
  #       reservations:
  #         memory: 24G
  #         devices:
  #           - driver: nvidia
  #             device_ids: ["all"]
  #             capabilities: [gpu]
  #   networks:
  #     - ambient-network
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health"]
  #     interval: 60s
  #     timeout: 30s
  #     retries: 10
  #     start_period: 1800s
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

networks:
  ambient-network:
    driver: bridge

volumes:
  api_uploads:
    driver: local
  api_logs:
    driver: local
  postgres_data:
    driver: local
